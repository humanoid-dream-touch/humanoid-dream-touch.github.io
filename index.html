<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Humanoid Dream Touch</title>
  <link rel="icon" href="./figs/egox_iconv2.png" type="image/png">
  <link rel="stylesheet" href="./css/bulma.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="style.css">

  <script defer src="./js/fontawesome.all.min.js"></script>
</head>
<body>
  <div class="toc">
    <h3>Content</h3>
    <hr>
    <ul>
      <li><a href="#abstract">Abstract</a></li>
      <li><a href="#wbc"> Whole-Body Control</a></li>
      <li><a href="#retargeting">Motion Retargeting</a></li>
      <li><a href="#touchdreaming">Touch Drearming</a></li>
      <!-- <li><a href="#acknowledgements">Acknowledgements</a></li> -->
    </ul>
  </div>

  <div class="main-content">
    <div class="hero-text">DreamTouch</div>
    <div class="sub-hero-text">Learning Dexterous Humanoid Manipulation with Touch Dreaming</div>

    <!-- Add Authors -->
    <!-- <div class="authors">
      <a href="https://yaruniu.com/" target="_blank">Yaru Niu</a><br>
      <a href="https://www.meche.engineering.cmu.edu/directory/bios/zhao-ding.html" target="_blank">Ding Zhao</a>
      <span class="affiliation">Carnegie Mellon University, Google Research</span>
      <span class="affiliation" style="color: #555; text-align: center; font-size: 20px; margin-top: 6px;">Under prepration for IROS 2026</span>
    </div> -->
    <!-- End Authors -->

    <!-- use the video ./figs/videomimic_teaser.mp4 -->
    <!-- <video id="teaser-video" src="./videos/Human2LocoMan： Learning Versatile Quadrupedal Manipulation with Human Pretraining [ay_-z9M18p0].webm" width="100%" height="100%" controls muted playsinline autoplay></video> -->
    <!-- <div class="youtube-video-container">
      <iframe
        src="https://www.youtube.com/embed/ay_-z9M18p0?autoplay=1&mute=1&loop=1&playlist=ay_-z9M18p0"
        title="Human2LocoMan Teaser"
        frameborder="0"
        allow="autoplay; encrypted-media; picture-in-picture"
        allowfullscreen>
      </iframe>
    </div> -->

    <!-- Caption for Figure 1 (Teaser Video) -->
    <!-- <p class="figure-caption">
        <span style="font-variant: small-caps;">DreamTouch</span> is an uniformed framework for cross-embodiment learning including data collection and model training.
    </p> -->

    <div class="column has-text-centered">
      <div class="publication-links">
        <!-- PDF Link. -->
        <span class="link-block">
          <a href="https://arxiv.org/pdf/2011.12948"
              class="external-link button is-normal is-rounded is-dark">
            <span class="icon">
                <i class="fas fa-file-pdf"></i>
            </span>
            <span>Paper</span>
          </a>
        </span>
        <span class="link-block">
          <a href="https://arxiv.org/abs/2011.12948"
              class="external-link button is-normal is-rounded is-dark">
            <span class="icon">
                <i class="ai ai-arxiv"></i>
            </span>
            <span>arXiv</span>
          </a>
        </span>
        <!-- Video Link. -->
        <span class="link-block">
          <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
              class="external-link button is-normal is-rounded is-dark">
            <span class="icon">
                <i class="fab fa-youtube"></i>
            </span>
            <span>Video</span>
          </a>
        </span>
        <!-- Code Link. -->
        <span class="link-block">
          <a href="https://github.com/google/nerfies"
              class="external-link button is-normal is-rounded is-dark">
            <span class="icon">
                <i class="fab fa-github"></i>
            </span>
            <span>Code</span>
            </a>
        </span>
        <!-- Dataset Link. -->
        <span class="link-block">
          <a href="https://github.com/google/nerfies/releases/tag/0.1"
              class="external-link button is-normal is-rounded is-dark">
            <span class="icon">
                <i class="far fa-images"></i>
            </span>
            <span>Data</span>
            </a>
        </span>
      </div>
    </div>
    
    <div class="tagline" id="abstract">Abstract.</div>
    <div class="paper-section">
      Learning from demonstrations across different embodiments is a very promising way for scaling up training data to achieve better generalizations.
      Based on this insight, we introduce EgoX, an uniformed framework for cross-embodiment learning which enables different robots -- humanoid, locoman, roboticarm -- to learn from human videos.
      In this work, we provide uniformed data collection and training pipelines for dexterous manipulation tasks, bridging the gap between different embodiments. 
    </div> 

    <!-- <div class="columns is-centered">  
      <div class="interpolation-panel"
        style="width: 1280px; height: 340px; background-color: #fff4cf; margin: 0 auto; border-radius: 12px; overflow: hidden; display: flex; align-items: center; justify-content: center;">
      <div id="viewer1" style="width: 98%; height: 95%;"></div></div>
      <div class="interpolation-panel"
        style="width: 1280px; height: 340px; background-color: #fff4cf; margin: 0 auto; border-radius: 12px; overflow: hidden; display: flex; align-items: center; justify-content: center;">
      <div id="viewer2" style="width: 98%; height: 95%;"></div></div>
      <div class="interpolation-panel"
        style="width: 1280px; height: 340px; background-color: #fff4cf; margin: 0 auto; border-radius: 12px; overflow: hidden; display: flex; align-items: center; justify-content: center;">
      <div id="viewer3" style="width: 98%; height: 95%;"></div></div>
    </div>
    <p class="figure-caption">
      <b>Robot Evolution</b> 
    </p> -->

    <div class="tagline" id="wbc">A Hierarchical Framework for Humanoid Whole-Body Control.</div>
    <a id="figure-3-img" href="image/wbc-2.png" download="wbc.png">
      <img src="image/wbc-2.png" alt="Whole-Body Control">
    </a>
    <!-- Caption for Figure 3 -->
    <p class="figure-caption">
      <b>Figure 1:</b> Teacher-student framework for lower-body control.
    </p>

    <div class="tagline" id="retargeting">Human-to-Robot Motion Retargeting.</div>
    <div class="column has-text-centered">
      <div class="better-video-frame">
      <video src="./videos/g1_nuts_pour.mp4" controls autoplay muted playsinline loop></video>
      </div>
    </div>
    <p class="figure-caption">
      <b>Data Collection for G1 Humanoid</b> 
    </p>
    
    <div class="video-gallery-section" id="humanoidGallerySection">
      <div class="video-gallery-container">
        <div class="video-gallery" id="videoGalleryHumanoid">
          <video class="gallery-video" src="./videos/banana_cut_cut.mp4" autoplay muted playsinline loop></video>
          <video class="gallery-video" src="./videos/cat_scoop_cut.mp4" autoplay muted playsinline loop></video>
          <video class="gallery-video" src="./videos/nuts_pour_bowl_cut2.mp4" autoplay muted playsinline loop></video>
          <video class="gallery-video" src="./videos/nuts_pour_cup_cut.mp4" autoplay muted playsinline loop></video>
          <video class="gallery-video" src="./videos/nuts_scoop_cut2.mp4" autoplay muted playsinline loop></video>
          <video class="gallery-video" src="./videos/toy_cut.mp4" autoplay muted playsinline loop></video>
        </div>
      </div>
      <div class="gallery-caption-container">
          <div class="gallery-nav-controls">
            <button class="gallery-nav left" id="scrollLeftBtnHumanoid">&lt;</button>
            <button class="gallery-nav right" id="scrollRightBtnHumanoid">&gt;</button>
          </div>
          <p class="figure-caption gallery-caption">
            <b>Versatile Manipulation Tasks including Tool Use:</b> Cutting bananas and toys, scooping nuts, and pouring them into bowls and cups — a diverse set of everyday manipulation tasks
          </p>
      </div>
    </div>

    <div class="tagline" id="touchdreaming">Humanoid Drearm Touch.</div>
    <!-- <div class="column has-text-centered">
      <div class="better-video-frame">
      <video src="./videos/embodiment_compare.mp4" controls autoplay muted playsinline loop></video>
      </div>
    </div> -->

    <!-- <div class="tagline" id="acknowledgements">Acknowledgements.</div>
    <div class="paper-section" style="margin-top: -5px;">
      <p>
        We thank Binghong for making this website.
      </p>
    </div>

    <div class="paper-bibtex-code" id="BibTex">
      <div class="paper-bibtex-title">BibTeX</div>
      <pre><code>@inproceedings{DreamTouch,
        title     = {Learning Dexterous Humanoid Manipulation with Touch Dreaming},
        author    = {Yaru Niu},
        booktitle = {Proceedings of the Conference on Robot Learning (IROS)},
        year      = {2026}
      }</code></pre>
    </div> -->

  </div> <!-- End of main-content div -->

  <div class="footer">
    <!-- © UC Berkeley | Powered by vision, motion, and a little ambition. -->
    © Carnegie Mellon | Webpage materials are adapted from <a href="https://github.com/videomimic-1/videomimic-1.github.io" target="_blank">VideoMimic</a> and <a href="https://github.com/nerfies/nerfies.github.io" target="_blank">Nerfies</a>.
  </div>

  <!-- <script type="module">
    import * as THREE from 'https://unpkg.com/three@0.160.0/build/three.module.js';
    import { GLTFLoader } from 'https://esm.sh/three@0.160.0/examples/jsm/loaders/GLTFLoader.js';

    function createViwer(containerId, glbPath, camerapos, cameralookat){
      const container = document.getElementById(containerId);
      const width = container.clientWidth, height = container.clientHeight;
      //camera
      const camera = new THREE.PerspectiveCamera( 70, width / height, 0.01, 10 );
      camera.position.copy(camerapos); //0.3,0.25,0.4
      camera.lookAt(cameralookat)
      //scene
      const scene = new THREE.Scene();
      scene.background = new THREE.Color(0xfffbec);
      //Lights
      const hemiLight = new THREE.HemisphereLight( 0xffffff, 0x8d8d8d, 3 );
      hemiLight.position.set( 0, 20, 0 );
      scene.add( hemiLight );

      const dirLight = new THREE.DirectionalLight( 0xffffff, 3 );
      dirLight.position.set( - 3, 10, - 10 );
      dirLight.castShadow = true;
      dirLight.shadow.camera.top = 2;
      dirLight.shadow.camera.bottom = - 2;
      dirLight.shadow.camera.left = - 2;
      dirLight.shadow.camera.right = 2;
      dirLight.shadow.camera.near = 0.1;
      dirLight.shadow.camera.far = 40;
      scene.add( dirLight );
      //Reander
      const renderer = new THREE.WebGLRenderer( { antialias: true } );
      renderer.setSize( width, height );
      container.appendChild( renderer.domElement );
      //Load model
      const loader = new GLTFLoader();
      let model = null;

      loader.load(
        glbPath, 
        function (gltf) {
          model = gltf.scene;
          model.scale.set(0.5, 0.5, 0.5); 
          scene.add(model);

          model.traverse((child) => {
            if (child.isMesh) {
              const edges = new THREE.EdgesGeometry(child.geometry, 60); 
              const line = new THREE.LineSegments(
                edges,
                new THREE.LineBasicMaterial({ color: 0x000000 })
              );
              child.add(line);
            }
          });
        },
      );

      // Move while hover the mouse
      let isHover = false;
      let lastX = 0;
      const initialRotationY = 0;
      const sensitivity = 0.002;
      const returnSpeed = 0.06;

      container.addEventListener('mouseenter', (e) => {
        isHover = true;
        lastX = e.clientX;
      });

      container.addEventListener('mousemove', (e) => {
        if (!isHover || !model) return;
        const deltaX = e.clientX - lastX;
        model.rotation.y += deltaX * sensitivity;
        lastX = e.clientX;
      });

      container.addEventListener('mouseleave', () => {
        isHover = false;
      });
      //animate
      function animate() {
        if (model && !isHover){
          model.rotation.y +=(initialRotationY - model.rotation.y) * returnSpeed;
        }
        renderer.render( scene, camera );
      }
      renderer.setAnimationLoop( animate );
    }
    const camerapos1 = new THREE.Vector3(0.23, 0.34, 0.37)
    const cameralookat1 = new THREE.Vector3(0.1, 0.25, 0)
    createViwer('viewer1','./glb/xARM7_leap_handv2.glb', camerapos1, cameralookat1);
    const camerapos2 = new THREE.Vector3(0.23, 0.13, 0.29)
    const cameralookat2 = new THREE.Vector3(0.05, -0.03, 0)
    createViwer('viewer2','./glb/LocoMan_v3.glb', camerapos2, cameralookat2);
    const camerapos3 = new THREE.Vector3(0.31, 0.13, 0.4)
    const cameralookat3 = new THREE.Vector3(0.05, -0.01, 0)
    createViwer('viewer3','./glb/Humanoid_v2.glb', camerapos3, cameralookat3);

  </script> -->

  <script>
    document.addEventListener('DOMContentLoaded', function() {
      const galleries = [
        {
          sectionId: 'humanoidGallerySection', 
          galleryInnerId: 'videoGalleryHumanoid',
          scrollLeftBtnId: 'scrollLeftBtnHumanoid',
          scrollRightBtnId: 'scrollRightBtnHumanoid'
        },
      ];

      galleries.forEach(galleryConfig => {
        const gallerySection = document.getElementById(galleryConfig.sectionId);
        if (!gallerySection) {
          console.error(`Gallery section with ID ${galleryConfig.sectionId} not found.`);
          return;
        }

        const galleryContainer = gallerySection.querySelector('.video-gallery-container');
        const galleryInner = document.getElementById(galleryConfig.galleryInnerId);
        const scrollLeftBtn = document.getElementById(galleryConfig.scrollLeftBtnId);
        const scrollRightBtn = document.getElementById(galleryConfig.scrollRightBtnId);

        if (galleryContainer && galleryInner && scrollLeftBtn && scrollRightBtn) {
          // Calculate the scroll amount based on the width of the first video + gap
          const scrollAmount = (galleryInner.firstElementChild?.offsetWidth || 300) + 15; // 15 is the gap

          scrollLeftBtn.addEventListener('click', () => {
            // Scroll the CONTAINER element
            galleryContainer.scrollBy({ left: -scrollAmount, behavior: 'smooth' });
          });

          scrollRightBtn.addEventListener('click', () => {
            // Scroll the CONTAINER element
            galleryContainer.scrollBy({ left: scrollAmount, behavior: 'smooth' });
          });

        } else {
          console.error(`Gallery elements not found for navigation setup in section ${galleryConfig.sectionId}.`);
          // Log which elements might be missing
          if (!galleryContainer) console.error('Missing element: .video-gallery-container in section ' + galleryConfig.sectionId);
          if (!galleryInner) console.error(`Missing element with ID ${galleryConfig.galleryInnerId}`);
          if (!scrollLeftBtn) console.error(`Missing element with ID ${galleryConfig.scrollLeftBtnId}`);
          if (!scrollRightBtn) console.error(`Missing element with ID ${galleryConfig.scrollRightBtnId}`);
        }
      });
    });
  </script>

</body>
</html>
